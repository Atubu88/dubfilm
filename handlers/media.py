import logging
import re
from dataclasses import dataclass
from pathlib import Path
from typing import Any

from aiogram import F, Router
from aiogram.fsm.context import FSMContext
from aiogram.fsm.state import State, StatesGroup
from aiogram.types import CallbackQuery, InlineKeyboardButton, InlineKeyboardMarkup, Message

from ai.service import AIService
from config import DEFAULT_TRANSLATION_CHOICES
from pipelines.summary import run_summary
from pipelines.transcribe import run_transcription
from pipelines.translate import run_translation
from handlers.subtitles import SubtitleState
from services.audio import MAX_FILE_SIZE_BYTES, get_media_size, prepare_audio_file
from services.downloader import download_audio_from_url, is_supported_media_url

router = Router()
logger = logging.getLogger(__name__)

URL_PATTERN = re.compile(r"(https?://\S+)", re.IGNORECASE)


class TranslationState(StatesGroup):
    waiting_for_language = State()


@dataclass
class TranscriptionResult:
    text: str
    language: str


LANG_MAP = {
    "English": "english",
    "Arabic": "arabic",
    "Uzbek": "uzbek",
    "Russian": "russian",
}


async def _get_ai_service(message: Message) -> AIService:
    ai_service: AIService = message.bot.ai_service
    return ai_service


async def _send_long_message(message: Message, text: str, chunk_size: int = 3900) -> None:
    if len(text) <= chunk_size:
        await message.answer(text)
        return

    for start in range(0, len(text), chunk_size):
        await message.answer(text[start:start + chunk_size])


async def _request_translation_language(message: Message, transcription: TranscriptionResult, state: FSMContext) -> None:
    options = ", ".join(DEFAULT_TRANSLATION_CHOICES)
    await state.update_data(text=transcription.text, language=transcription.language)
    await state.set_state(TranslationState.waiting_for_language)
    keyboard = InlineKeyboardMarkup(
        inline_keyboard=[
            [
                InlineKeyboardButton(
                    text=choice,
                    callback_data=f"translation:{LANG_MAP[choice]}",
                )
            ]
            for choice in DEFAULT_TRANSLATION_CHOICES
        ]
    )
    await message.answer(
        (
            "Ð“Ð¾Ñ‚Ð¾Ð²Ð¾! Ð¯ Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»Ð¸Ð» ÑÐ·Ñ‹Ðº: {lang}. ÐÐ° ÐºÐ°ÐºÐ¾Ð¹ ÑÐ·Ñ‹Ðº Ð¿ÐµÑ€ÐµÐ²ÐµÑÑ‚Ð¸?\n"
            "Ð’Ð°Ñ€Ð¸Ð°Ð½Ñ‚Ñ‹: {options}\n"
            "Ð’Ñ‹Ð±Ð¸Ñ€Ð°Ð¹ ÑÐ·Ñ‹Ðº Ð¿ÐµÑ€ÐµÐ²Ð¾Ð´Ð° ÐºÐ½Ð¾Ð¿ÐºÐ¾Ð¹ Ð½Ð¸Ð¶Ðµ."
        ).format(lang=transcription.language.title(), options=options),
        reply_markup=keyboard,
    )


def _is_supported_document(message: Message) -> bool:
    if not message.document:
        return False
    mime = message.document.mime_type or ""
    return mime.startswith("audio/") or mime.startswith("video/")


def _extract_supported_url(text: str) -> str | None:
    for match in URL_PATTERN.finditer(text):
        url = match.group(1)
        if is_supported_media_url(url):
            return url
    return None


async def _process_audio(
    message: Message, state: FSMContext, ai_service: AIService, audio_path: Path
) -> None:
    try:
        transcription_data = await run_transcription(audio_path=audio_path, ai_service=ai_service)
    except Exception:
        logger.exception("Failed to transcribe audio %s", audio_path)
        await message.answer("ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ñ‚ÑŒ Ð°ÑƒÐ´Ð¸Ð¾. ÐŸÐ¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹ ÐµÑ‰Ñ‘ Ñ€Ð°Ð· Ð¸Ð»Ð¸ Ð¿Ð¾Ð·Ð¶Ðµ.")
        return
    finally:
        try:
            audio_path.unlink(missing_ok=True)
        except OSError:
            pass

        parent = audio_path.parent
        if parent.name.startswith("download_"):
            try:
                parent.rmdir()
            except OSError:
                pass

    transcription = TranscriptionResult(
        text=transcription_data["text"],
        language=transcription_data["language"],
    )

    await _request_translation_language(message, transcription, state)


async def _translate_and_summarize(
    message: Message, state: FSMContext, target_language: str
) -> None:
    ai_service = await _get_ai_service(message)
    data: dict[str, Any] = await state.get_data()

    original_text = data.get("text", "")
    detected_language = data.get("language", "unknown")

    if not original_text:
        await state.clear()
        await message.answer("ÐÐµ Ð½Ð°ÑˆÑ‘Ð» Ñ‚ÐµÐºÑÑ‚ Ð´Ð»Ñ Ð¿ÐµÑ€ÐµÐ²Ð¾Ð´Ð°, Ð¿Ñ€Ð¸ÑˆÐ»Ð¸ Ð°ÑƒÐ´Ð¸Ð¾/Ð²Ð¸Ð´ÐµÐ¾ Ð·Ð°Ð½Ð¾Ð²Ð¾.")
        return

    await message.answer("ÐŸÐµÑ€ÐµÐ²Ð¾Ð¶Ñƒ Ð¸ Ð³Ð¾Ñ‚Ð¾Ð²Ð»ÑŽ ÐºÑ€Ð°Ñ‚ÐºÐ¾Ðµ Ñ€ÐµÐ·ÑŽÐ¼Ðµ...")

    translation = await run_translation(
        text=original_text,
        source_language=detected_language,
        target_language=target_language,
        ai_service=ai_service,
    )

    summary_text = await run_summary(
        original_text=original_text,
        translated_text=translation,
        target_language=target_language,
        ai_service=ai_service,
    )

    # âœ… Ð˜Ð—ÐœÐ•ÐÐÐ Ð¢ÐžÐ›Ð¬ÐšÐž Ð¤ÐžÐ ÐœÐÐ¢ Ð¡ÐžÐžÐ‘Ð©Ð•ÐÐ˜Ð¯
    response = (
        "ðŸ“ Ð¡ÑƒÑ‚ÑŒ Ð²Ð¸Ð´ÐµÐ¾:\n\n"
        "{summary}\n\n"
        "â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
        "ðŸ—£ ÐžÑ€Ð¸Ð³Ð¸Ð½Ð°Ð» ({src}):\n{orig}\n\n"
        "ðŸŒ ÐŸÐµÑ€ÐµÐ²Ð¾Ð´ ({target}):\n{translated}"
    ).format(
        summary=summary_text,
        src=detected_language.title(),
        orig=original_text,
        target=target_language.title(),
        translated=translation,
    )

    await _send_long_message(message, response)
    await state.clear()


@router.message(F.audio | F.voice | F.video | F.video_note | F.document)
async def handle_media(message: Message, state: FSMContext) -> None:
    current_state = await state.get_state()
    if current_state in {
        SubtitleState.waiting_for_video.state,
        SubtitleState.choosing_subtitle_language.state,
        SubtitleState.generating.state,
        SubtitleState.sending_result.state,
    }:
        return

    data = await state.get_data()
    if data.get("processing"):
        await message.answer("Ð¯ ÑƒÐ¶Ðµ Ð¾Ð±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°ÑŽ Ð¿Ñ€ÐµÐ´Ñ‹Ð´ÑƒÑ‰Ð¸Ð¹ Ð·Ð°Ð¿Ñ€Ð¾Ñ, Ð¿Ð¾Ð´Ð¾Ð¶Ð´Ð¸, Ð¿Ð¾Ð¶Ð°Ð»ÑƒÐ¹ÑÑ‚Ð°.")
        return

    if message.document and not _is_supported_document(message):
        await message.answer("ÐŸÐ¾Ð´Ð´ÐµÑ€Ð¶Ð¸Ð²Ð°ÑŽÑ‚ÑÑ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð°ÑƒÐ´Ð¸Ð¾ Ð¸Ð»Ð¸ Ð²Ð¸Ð´ÐµÐ¾ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ñ‹.")
        return

    file_size = get_media_size(message)
    if file_size is not None and file_size > MAX_FILE_SIZE_BYTES:
        await message.answer("Ð¤Ð°Ð¹Ð» ÑÐ»Ð¸ÑˆÐºÐ¾Ð¼ Ð±Ð¾Ð»ÑŒÑˆÐ¾Ð¹. ÐœÐ°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ñ€Ð°Ð·Ð¼ÐµÑ€ â€” 20 ÐœÐ‘.")
        return

    ai_service = await _get_ai_service(message)

    await state.update_data(processing=True)
    try:
        await message.answer("Ð¡ÐºÐ°Ñ‡Ð¸Ð²Ð°ÑŽ Ð¸ Ð¾Ð±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°ÑŽ Ñ„Ð°Ð¹Ð», ÑÐµÐºÑƒÐ½Ð´Ñƒ...")
        audio_path = await prepare_audio_file(bot=message.bot, media=message)
        await _process_audio(message, state, ai_service, audio_path)
    except Exception:
        logger.exception(
            "Failed to process uploaded media from user %s",
            message.from_user.id if message.from_user else "unknown"
        )
        await message.answer("ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ ÑÐºÐ°Ñ‡Ð°Ñ‚ÑŒ Ð¸Ð»Ð¸ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ñ‚ÑŒ Ñ„Ð°Ð¹Ð». ÐŸÑ€Ð¾Ð²ÐµÑ€ÑŒ ÐµÐ³Ð¾ Ð¸ Ð¿Ð¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹ ÑÐ½Ð¾Ð²Ð° Ñ‡ÑƒÑ‚ÑŒ Ð¿Ð¾Ð·Ð¶Ðµ.")
    finally:
        await state.update_data(processing=False)


@router.message(F.text.regexp(URL_PATTERN))
async def handle_media_links(message: Message, state: FSMContext) -> None:
    current_state = await state.get_state()
    if current_state in {
        SubtitleState.waiting_for_video.state,
        SubtitleState.choosing_subtitle_language.state,
        SubtitleState.generating.state,
        SubtitleState.sending_result.state,
    }:
        return

    data = await state.get_data()
    if data.get("processing"):
        return

    url = _extract_supported_url(message.text or "")
    if not url:
        return

    ai_service = await _get_ai_service(message)

    await state.update_data(processing=True)
    try:
        await message.answer("Ð¡ÐºÐ°Ñ‡Ð¸Ð²Ð°ÑŽ Ð¼ÐµÐ´Ð¸Ð° Ð¿Ð¾ ÑÑÑ‹Ð»ÐºÐµ, ÑÐµÐºÑƒÐ½Ð´Ñƒ...")
        audio_path = await download_audio_from_url(url)
        await _process_audio(message, state, ai_service, audio_path)
    except Exception:
        logger.exception("Failed to download media from %s", url)
        await message.answer("ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ ÑÐºÐ°Ñ‡Ð°Ñ‚ÑŒ Ð¸Ð»Ð¸ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ñ‚ÑŒ ÑÑÑ‹Ð»ÐºÑƒ. ÐŸÑ€Ð¾Ð²ÐµÑ€ÑŒ ÐµÑ‘ Ð¸ Ð¿Ð¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹ ÑÐ½Ð¾Ð²Ð°.")
    finally:
        await state.update_data(processing=False)


@router.message(TranslationState.waiting_for_language)
async def handle_translation_request(message: Message, state: FSMContext) -> None:
    await message.answer("ÐŸÐ¾Ð¶Ð°Ð»ÑƒÐ¹ÑÑ‚Ð°, Ð²Ñ‹Ð±ÐµÑ€Ð¸ ÑÐ·Ñ‹Ðº ÐºÐ½Ð¾Ð¿ÐºÐ¾Ð¹ Ð½Ð¸Ð¶Ðµ â¬‡ï¸")


@router.callback_query(TranslationState.waiting_for_language, F.data.startswith("translation:"))
async def handle_translation_button(callback: CallbackQuery, state: FSMContext) -> None:
    target_language = callback.data.split(":", 1)[1].title()
    await callback.answer()
    if callback.message:
        await _translate_and_summarize(callback.message, state, target_language)
