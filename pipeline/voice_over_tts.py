# pipeline/voice_over_tts.py

import io
import json
import math
import os
import shutil
import subprocess
import tempfile
import wave
from dataclasses import dataclass
from typing import List

from openai import OpenAI
from pydub import AudioSegment, effects

from config import OPENAI_API_KEY
from pipeline.constants import OUTPUT_DIR, TRANSLATION_DIR, WHISPER_DIR

client = OpenAI(api_key=OPENAI_API_KEY)

TRANSLATED_JSON = os.path.join(TRANSLATION_DIR, "translated.json")
TRANSCRIPT_JSON = os.path.join(WHISPER_DIR, "transcript.json")
MP3_OUTPUT = os.path.join(OUTPUT_DIR, "voice_over_tts.mp3")
WAV_OUTPUT = os.path.join(OUTPUT_DIR, "voice_over_tts.wav")
FINAL_AUDIO = os.path.join(OUTPUT_DIR, "final_audio.wav")
VOICE_CACHE_DIR = os.path.join(OUTPUT_DIR, "voice_over_segments")

TARGET_SAMPLE_RATE = 16000
TOLERANCE_MS = 10
SILENCE_TAIL_MS = 500

# —Å–µ–π—á–∞—Å –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º, –Ω–æ –æ—Å—Ç–∞–≤–ª—è–µ–º –Ω–∞ –±—É–¥—É—â–µ–µ
MIN_STRETCH_RATIO = 0.9


@dataclass
class Segment:
    id: int
    start: float
    end: float
    text: str

    @property
    def duration_ms(self) -> int:
        return max(int(round((self.end - self.start) * 1000)), 0)


class VoiceOverError(RuntimeError):
    pass


# -------------------------------------------------------------------
# –ó–∞–≥—Ä—É–∑–∫–∞ —Å–µ–≥–º–µ–Ω—Ç–æ–≤
# -------------------------------------------------------------------
def load_translated_segments() -> List[Segment]:
    if not os.path.exists(TRANSLATED_JSON):
        raise VoiceOverError("‚ùå translated.json not found ‚Äî cannot build voice-over track")

    with open(TRANSLATED_JSON, "r", encoding="utf-8") as f:
        data = json.load(f)

    if not isinstance(data, list):
        raise VoiceOverError("‚ùå translated.json has unexpected format (expected a list)")

    segments: List[Segment] = []
    for raw in data:
        text = (raw.get("dst") or "").strip()
        if not text:
            continue

        start = float(raw.get("start", 0.0))
        end = float(raw.get("end", start))
        if end <= start:
            continue

        segment_id = int(raw.get("id", len(segments)))
        segments.append(Segment(id=segment_id, start=start, end=end, text=text))

    if not segments:
        raise VoiceOverError("‚ùå No translated segments with text found")

    print(f"üìÑ Loaded {len(segments)} translated segments for voice-over")
    return segments


def load_original_duration(segments: List[Segment]) -> float:
    if os.path.exists(TRANSCRIPT_JSON):
        with open(TRANSCRIPT_JSON, "r", encoding="utf-8") as f:
            meta = json.load(f)
        duration = meta.get("duration")
        if isinstance(duration, (int, float)) and duration > 0:
            return float(duration)

    return max((seg.end for seg in segments), default=0.0)


# -------------------------------------------------------------------
# –õ—ë–≥–∫–∞—è ¬´–æ–∂–∏–≤–ª—è—é—â–∞—è¬ª –æ–±—Ä–∞–±–æ—Ç–∫–∞
# -------------------------------------------------------------------
def apply_loudness_drift(audio: AudioSegment, depth_db: float = 1.0) -> AudioSegment:
    import random

    drifted = AudioSegment.empty()
    chunk_ms = 120  # –º–∞–ª–µ–Ω—å–∫–∏–µ —à–∞–≥–∏ –¥–ª—è –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –∫–æ–ª–µ–±–∞–Ω–∏–π

    for i in range(0, len(audio), chunk_ms):
        chunk = audio[i:i + chunk_ms]
        shift = random.uniform(-depth_db, depth_db)
        drifted += chunk + shift

    return drifted


def add_presence(audio: AudioSegment) -> AudioSegment:
    # —á—É—Ç—å –ø–æ–¥–Ω–∏–º–∞–µ–º ¬´—Å–µ—Ä–µ–¥–∏–Ω—É¬ª, –Ω–æ –º—è–≥–∫–æ
    return audio + audio.high_pass_filter(180) - 2


def apply_random_eq(audio: AudioSegment) -> AudioSegment:
    import random

    low = random.uniform(70, 110)
    high = random.uniform(11500, 13500)
    return audio.high_pass_filter(low).low_pass_filter(high)


# -------------------------------------------------------------------
# –°–∏–Ω—Ç–µ–∑ TTS + –ª—ë–≥–∫–∏–π mastering
# -------------------------------------------------------------------
def synthesize_text_to_audio(text: str) -> AudioSegment:
    print(f"üîä Synthesizing TTS for: {text[:60]}{'‚Ä¶' if len(text) > 60 else ''}")
    response = client.audio.speech.create(
        model="gpt-4o-mini-tts",
        voice="echo",          # –º—É–∂—Å–∫–æ–π –≥–æ–ª–æ—Å, –∫–∞–∫ —Ç—ã –ø–æ—Å—Ç–∞–≤–∏–ª
        input=text,
        response_format="wav",
    )

    audio_bytes = response.read()
    buffer = io.BytesIO(audio_bytes)
    audio = AudioSegment.from_file(buffer, format="wav")

    # –±–∞–∑–æ–≤–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
    audio = audio.set_channels(1).set_frame_rate(TARGET_SAMPLE_RATE)
    audio = audio.fade_in(5).fade_out(15)

    audio = effects.normalize(audio, headroom=1.2)
    audio = effects.compress_dynamic_range(
        audio,
        threshold=-27.0,
        ratio=2.2,
        attack=6,
        release=140,
    )

    # –¥–æ–±–∞–≤–ª—è–µ–º ¬´–∂–∏–≤–æ—Å—Ç—å¬ª
    audio = apply_loudness_drift(audio, depth_db=0.8)
    audio = add_presence(audio)

    # –ª—ë–≥–∫–∞—è –≤–∞—Ä–∏–∞—Ç–∏–≤–Ω–æ—Å—Ç—å EQ
    audio = apply_random_eq(audio)

    return audio


# -------------------------------------------------------------------
# (–æ—Å—Ç–∞–≤–ª—è–µ–º –Ω–∞ –±—É–¥—É—â–µ–µ, —Å–µ–π—á–∞—Å –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º)
# -------------------------------------------------------------------
def build_atempo_chain(ratio: float) -> str:
    if ratio <= 0:
        raise VoiceOverError("‚ùå Invalid tempo ratio computed")

    filters = []
    temp_ratio = ratio
    while temp_ratio < 0.5 or temp_ratio > 2.0:
        if temp_ratio < 0.5:
            filters.append("atempo=0.5")
            temp_ratio /= 0.5
        else:
            filters.append("atempo=2.0")
            temp_ratio /= 2.0
    filters.append(f"atempo={temp_ratio:.4f}")
    return ",".join(filters)


def stretch_with_ffmpeg(audio: AudioSegment, ratio: float) -> AudioSegment:
    os.makedirs(VOICE_CACHE_DIR, exist_ok=True)
    with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as tmp_in:
        audio.export(tmp_in.name, format="wav")
        input_path = tmp_in.name

    with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as tmp_out:
        output_path = tmp_out.name

    try:
        filter_chain = build_atempo_chain(ratio)
        cmd = [
            "ffmpeg",
            "-y",
            "-i",
            input_path,
            "-filter:a",
            filter_chain,
            output_path,
        ]
        result = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
        if result.returncode != 0:
            raise VoiceOverError("‚ùå Failed to stretch audio via ffmpeg")
        stretched = AudioSegment.from_file(output_path, format="wav")
        stretched = stretched.set_channels(1).set_frame_rate(TARGET_SAMPLE_RATE)
    finally:
        for path in (input_path, output_path):
            try:
                os.remove(path)
            except FileNotFoundError:
                pass

    return stretched


# -------------------------------------------------------------------
# –ú–∞—Ç—á–∏–Ω–≥ –ø–æ –¥–ª–∏–Ω–µ: —Ç–æ–ª—å–∫–æ –ø–∞–¥–¥–∏–Ω–≥, –±–µ–∑ –æ–±—Ä–µ–∑–∫–∏
# -------------------------------------------------------------------
def match_duration(audio: AudioSegment, target_ms: int) -> AudioSegment:
    current_ms = len(audio)

    # –ù–µ–±–æ–ª—å—à–∏–µ —Ä–∞—Å—Ö–æ–∂–¥–µ–Ω–∏—è –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º, —á—Ç–æ–±—ã –Ω–µ —Ä–µ–∑–∞—Ç—å –¥—ã—Ö–∞–Ω–∏–µ
    if abs(current_ms - target_ms) <= TOLERANCE_MS:
        return audio

    # –ï—Å–ª–∏ TTS –∫–æ—Ä–æ—á–µ –æ–∫–Ω–∞ ‚Üí –¥–æ–±–∞–≤–ª—è–µ–º —Ç–∏—à–∏–Ω—É
    if current_ms < target_ms:
        return audio + AudioSegment.silent(duration=target_ms - current_ms)

    # –ï—Å–ª–∏ TTS –¥–ª–∏–Ω–Ω–µ–µ ‚Üí –º—è–≥–∫–æ —Ä–µ–∂–µ–º –ø–æ —Ü–µ–ª–µ–≤–æ–º—É –æ–∫–Ω—É, —á—Ç–æ–±—ã –Ω–µ —Ä–∞–∑–¥–≤–∏–≥–∞—Ç—å —Ç–∞–π–º–ª–∞–π–Ω
    trimmed = audio[:target_ms]
    fade_out_ms = min(40, max(8, int(target_ms * 0.05)))
    return trimmed.fade_out(fade_out_ms)


# -------------------------------------------------------------------
# –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ —Ç–∞–π–º–ª–∞–π–Ω–∞ –ë–ï–ó –ü–ï–†–ï–ö–†–´–¢–ò–ô
# -------------------------------------------------------------------
def place_segments_on_timeline(segments: List[Segment], total_duration: float) -> AudioSegment:
    sorted_segments = sorted(segments, key=lambda s: s.start)
    placements = []
    current_position_ms = 0

    for seg in sorted_segments:
        target_ms = seg.duration_ms
        if target_ms <= 0:
            continue

        synthesized = synthesize_text_to_audio(seg.text)
        tts_audio = match_duration(synthesized, target_ms)

        requested_start_ms = int(seg.start * 1000)

        # –ö–õ–Æ–ß–ï–í–û–ï: —Å–µ–≥–º–µ–Ω—Ç –ù–ò–ö–û–ì–î–ê –Ω–µ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Ä–∞–Ω—å—à–µ –æ–∫–æ–Ω—á–∞–Ω–∏—è –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ
        position_ms = max(requested_start_ms, current_position_ms)
        end_ms = position_ms + len(tts_audio)

        placements.append((seg, tts_audio, position_ms))
        current_position_ms = end_ms

        print(
            f"  ‚Ä¢ Segment {seg.id}: start={seg.start:.2f}s end={seg.end:.2f}s "
            f"tts={len(tts_audio) / 1000:.2f}s placed_at={position_ms / 1000:.2f}s"
        )

    timeline_duration_ms = max(int(math.ceil(total_duration * 1000)), current_position_ms) + SILENCE_TAIL_MS
    print(f"üß± Building voice-over timeline of {timeline_duration_ms / 1000:.2f}s")

    final_audio = AudioSegment.silent(duration=timeline_duration_ms, frame_rate=TARGET_SAMPLE_RATE)

    for seg, tts_audio, position_ms in placements:
        final_audio = final_audio.overlay(tts_audio, position=position_ms)

    return final_audio


# -------------------------------------------------------------------
# –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏ —ç–∫—Å–ø–æ—Ä—Ç
# -------------------------------------------------------------------
def sanity_check_wav(path: str, min_duration: float) -> None:
    if not os.path.exists(path):
        raise VoiceOverError(f"‚ùå WAV not found ‚Üí {path}")

    if os.path.getsize(path) == 0:
        raise VoiceOverError("‚ùå WAV file is empty")

    with wave.open(path, "rb") as wav_file:
        frames = wav_file.getnframes()
        rate = wav_file.getframerate()
        duration = frames / float(rate)

    print(f"üîé Voice-over WAV duration: {duration:.2f}s")
    if duration < min_duration:
        raise VoiceOverError(
            f"‚ùå Voice-over WAV too short ({duration:.2f}s). Expected at least {min_duration:.2f}s"
        )


def export_audio_track(audio: AudioSegment) -> None:
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    audio = audio.set_channels(1).set_frame_rate(TARGET_SAMPLE_RATE)
    audio.export(WAV_OUTPUT, format="wav")
    audio.export(MP3_OUTPUT, format="mp3")
    shutil.copyfile(WAV_OUTPUT, FINAL_AUDIO)
    print(f"üíæ Saved WAV ‚Üí {WAV_OUTPUT}")
    print(f"üíæ Saved MP3 ‚Üí {MP3_OUTPUT}")
    print(f"üì¶ Copied voice-over track to FINAL_AUDIO ‚Üí {FINAL_AUDIO}")


# -------------------------------------------------------------------
# MAIN
# -------------------------------------------------------------------
def generate_voice_over_track():
    segments = load_translated_segments()
    total_duration = load_original_duration(segments)
    if total_duration <= 0:
        raise VoiceOverError("‚ùå Unable to determine original duration")

    final_audio = place_segments_on_timeline(segments, total_duration)
    export_audio_track(final_audio)
    sanity_check_wav(WAV_OUTPUT, min_duration=max(0.5, total_duration - 0.5))
    print("üü¢ Voice-over track ready!")


if __name__ == "__main__":
    generate_voice_over_track()