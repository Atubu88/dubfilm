import io
import json
import math
import os
import shutil
import subprocess
import tempfile
import wave
from dataclasses import dataclass
from typing import List

from openai import OpenAI
from pydub import AudioSegment, effects

from config import OPENAI_API_KEY, OUTPUT_DIR, TRANSLATION_DIR, WHISPER_DIR

client = OpenAI(api_key=OPENAI_API_KEY)

TRANSLATED_JSON = os.path.join(TRANSLATION_DIR, "translated.json")
TRANSCRIPT_JSON = os.path.join(WHISPER_DIR, "transcript.json")
MP3_OUTPUT = os.path.join(OUTPUT_DIR, "voice_over_tts.mp3")
WAV_OUTPUT = os.path.join(OUTPUT_DIR, "voice_over_tts.wav")
FINAL_AUDIO = os.path.join(OUTPUT_DIR, "final_audio.wav")
VOICE_CACHE_DIR = os.path.join(OUTPUT_DIR, "voice_over_segments")

TARGET_SAMPLE_RATE = 16000
TOLERANCE_MS = 10
SILENCE_TAIL_MS = 500

MIN_STRETCH_RATIO = 0.9  # below this, do not stretch ‚Äî just pad with silence


@dataclass
class Segment:
    id: int
    start: float
    end: float
    text: str

    @property
    def duration_ms(self) -> int:
        return max(int(round((self.end - self.start) * 1000)), 0)


class VoiceOverError(RuntimeError):
    pass


def load_translated_segments() -> List[Segment]:
    if not os.path.exists(TRANSLATED_JSON):
        raise VoiceOverError("‚ùå translated.json not found ‚Äî cannot build voice-over track")

    with open(TRANSLATED_JSON, "r", encoding="utf-8") as f:
        data = json.load(f)

    if not isinstance(data, list):
        raise VoiceOverError("‚ùå translated.json has unexpected format (expected a list)")

    segments: List[Segment] = []
    for raw in data:
        text = (raw.get("dst") or "").strip()
        if not text:
            continue

        start = float(raw.get("start", 0.0))
        end = float(raw.get("end", start))
        if end <= start:
            continue

        segment_id = int(raw.get("id", len(segments)))
        segments.append(Segment(id=segment_id, start=start, end=end, text=text))

    if not segments:
        raise VoiceOverError("‚ùå No translated segments with text found")

    print(f"üìÑ Loaded {len(segments)} translated segments for voice-over")
    return segments


def load_original_duration(segments: List[Segment]) -> float:
    if os.path.exists(TRANSCRIPT_JSON):
        with open(TRANSCRIPT_JSON, "r", encoding="utf-8") as f:
            meta = json.load(f)
        duration = meta.get("duration")
        if isinstance(duration, (int, float)) and duration > 0:
            return float(duration)

    return max((seg.end for seg in segments), default=0.0)


def apply_loudness_drift(audio: AudioSegment, depth_db=1.0) -> AudioSegment:
    import random
    from pydub.effects import compress_dynamic_range

    drifted = AudioSegment.empty()
    chunk_ms = 120  # –º–∞–ª–µ–Ω—å–∫–∏–µ –ø–æ—Ä—Ü–∏–∏ –¥–ª—è ¬´–∂–∏–≤–æ—Å—Ç–∏¬ª

    for i in range(0, len(audio), chunk_ms):
        chunk = audio[i:i+chunk_ms]
        shift = random.uniform(-depth_db, depth_db)
        drifted += chunk + shift

    return drifted


def add_presence(audio: AudioSegment) -> AudioSegment:
    return audio + audio.high_pass_filter(180) - 2  # +presence, –Ω–æ –º—è–≥–∫–æ



def apply_random_eq(audio: AudioSegment) -> AudioSegment:
    import random
    low = random.uniform(70, 110)
    high = random.uniform(11500, 13500)
    return audio.high_pass_filter(low).low_pass_filter(high)



def synthesize_text_to_audio(text: str) -> AudioSegment:
    print(f"üîä Synthesizing TTS for: {text[:60]}{'‚Ä¶' if len(text) > 60 else ''}")
    response = client.audio.speech.create(
        model="gpt-4o-mini-tts",
        voice="echo",
        input=text,
        response_format="wav",
    )

    audio_bytes = response.read()
    buffer = io.BytesIO(audio_bytes)
    audio = AudioSegment.from_file(buffer, format="wav")

    # ---- –±–∞–∑–æ–≤–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ ----
    audio = audio.set_channels(1).set_frame_rate(TARGET_SAMPLE_RATE)
    audio = audio.fade_in(5).fade_out(15)

    audio = effects.normalize(audio, headroom=1.2)
    audio = effects.compress_dynamic_range(
        audio,
        threshold=-27.0,
        ratio=2.2,
        attack=6,
        release=140,
    )

    # ---- –¥–æ–±–∞–≤–ª—è–µ–º "–∂–∏–≤–æ—Å—Ç—å" ----
    audio = apply_loudness_drift(audio, depth_db=0.8)
    audio = add_presence(audio)

    # ---- –ª—ë–≥–∫–∞—è –≤–∞—Ä–∏–∞—Ç–∏–≤–Ω–æ—Å—Ç—å EQ –¥–ª—è –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏ ----
    audio = apply_random_eq(audio)

    return audio



def build_atempo_chain(ratio: float) -> str:
    if ratio <= 0:
        raise VoiceOverError("‚ùå Invalid tempo ratio computed")

    filters = []
    temp_ratio = ratio
    while temp_ratio < 0.5 or temp_ratio > 2.0:
        if temp_ratio < 0.5:
            filters.append("atempo=0.5")
            temp_ratio /= 0.5
        else:
            filters.append("atempo=2.0")
            temp_ratio /= 2.0
    filters.append(f"atempo={temp_ratio:.4f}")
    return ",".join(filters)


def stretch_with_ffmpeg(audio: AudioSegment, ratio: float) -> AudioSegment:
    os.makedirs(VOICE_CACHE_DIR, exist_ok=True)
    with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as tmp_in:
        audio.export(tmp_in.name, format="wav")
        input_path = tmp_in.name

    with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as tmp_out:
        output_path = tmp_out.name

    try:
        filter_chain = build_atempo_chain(ratio)
        cmd = [
            "ffmpeg",
            "-y",
            "-i",
            input_path,
            "-filter:a",
            filter_chain,
            output_path,
        ]
        result = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
        if result.returncode != 0:
            raise VoiceOverError("‚ùå Failed to stretch audio via ffmpeg")
        stretched = AudioSegment.from_file(output_path, format="wav")
        stretched = stretched.set_channels(1).set_frame_rate(TARGET_SAMPLE_RATE)
    finally:
        for path in (input_path, output_path):
            try:
                os.remove(path)
            except FileNotFoundError:
                pass

    return stretched

def match_duration(audio: AudioSegment, target_ms: int) -> AudioSegment:
    current_ms = len(audio)

    # –ï—Å–ª–∏ TTS –∫–æ—Ä–æ—á–µ –æ–∫–Ω–∞ ‚Üí –¥–æ–±–∞–≤–ª—è–µ–º —Ç–∏—à–∏–Ω—É
    if current_ms < target_ms:
        return audio + AudioSegment.silent(duration=target_ms - current_ms)

    # –ï—Å–ª–∏ TTS –¥–ª–∏–Ω–Ω–µ–µ ‚Üí –æ—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ –µ—Å—Ç—å (–ù–ò–ö–û–ì–î–ê –Ω–µ –æ–±—Ä–µ–∑–∞–µ–º)
    return audio


def place_segments_on_timeline(segments: List[Segment], total_duration: float) -> AudioSegment:
    sorted_segments = sorted(segments, key=lambda s: s.start)
    placements = []
    current_position_ms = 0

    for seg in sorted_segments:
        target_ms = seg.duration_ms
        if target_ms <= 0:
            continue

        synthesized = synthesize_text_to_audio(seg.text)
        stretched = match_duration(synthesized, target_ms)

        requested_start_ms = int(seg.start * 1000)
        position_ms = max(requested_start_ms, current_position_ms)
        end_ms = position_ms + len(stretched)

        placements.append((seg, stretched, position_ms))
        current_position_ms = end_ms

        print(
            f"  ‚Ä¢ Segment {seg.id}: start={seg.start:.2f}s end={seg.end:.2f}s "
            f"tts={len(stretched) / 1000:.2f}s placed_at={position_ms / 1000:.2f}s"
        )

    timeline_duration_ms = max(int(math.ceil(total_duration * 1000)), current_position_ms) + SILENCE_TAIL_MS
    print(f"üß± Building voice-over timeline of {timeline_duration_ms / 1000:.2f}s")
    final_audio = AudioSegment.silent(duration=timeline_duration_ms, frame_rate=TARGET_SAMPLE_RATE)

    for seg, stretched, position_ms in placements:
        final_audio = final_audio.overlay(stretched, position=position_ms)

    return final_audio


def sanity_check_wav(path: str, min_duration: float) -> None:
    if not os.path.exists(path):
        raise VoiceOverError(f"‚ùå WAV not found ‚Üí {path}")

    if os.path.getsize(path) == 0:
        raise VoiceOverError("‚ùå WAV file is empty")

    with wave.open(path, "rb") as wav_file:
        frames = wav_file.getnframes()
        rate = wav_file.getframerate()
        duration = frames / float(rate)

    print(f"üîé Voice-over WAV duration: {duration:.2f}s")
    if duration < min_duration:
        raise VoiceOverError(
            f"‚ùå Voice-over WAV too short ({duration:.2f}s). Expected at least {min_duration:.2f}s"
        )


def export_audio_track(audio: AudioSegment) -> None:
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    audio = audio.set_channels(1).set_frame_rate(TARGET_SAMPLE_RATE)
    audio.export(WAV_OUTPUT, format="wav")
    audio.export(MP3_OUTPUT, format="mp3")
    shutil.copyfile(WAV_OUTPUT, FINAL_AUDIO)
    print(f"üíæ Saved WAV ‚Üí {WAV_OUTPUT}")
    print(f"üíæ Saved MP3 ‚Üí {MP3_OUTPUT}")
    print(f"üì¶ Copied voice-over track to FINAL_AUDIO ‚Üí {FINAL_AUDIO}")


def generate_voice_over_track():
    segments = load_translated_segments()
    total_duration = load_original_duration(segments)
    if total_duration <= 0:
        raise VoiceOverError("‚ùå Unable to determine original duration")

    final_audio = place_segments_on_timeline(segments, total_duration)
    export_audio_track(final_audio)
    sanity_check_wav(WAV_OUTPUT, min_duration=max(0.5, total_duration - 0.5))
    print("üü¢ Voice-over track ready!")


if __name__ == "__main__":
    generate_voice_over_track()