import json
import os
import re
import time

import requests
from openai import OpenAI
from pydub import AudioSegment
from pydub.silence import split_on_silence

from config import OPENAI_API_KEY, ASSEMBLYAI_API_KEY, TRANSCRIBE_PROVIDER
from helpers.gpt_cleaner import clean_segments_with_gpt
from helpers.validators import assert_valid_whisper
from pipeline.constants import AUDIO_DIR, WHISPER_DIR

client = OpenAI(api_key=OPENAI_API_KEY)
ASSEMBLYAI_API_URL = "https://api.assemblyai.com/v2"


# ============================================================
# ‚≠ê 1. –ü–†–û–§–ï–°–°–ò–û–ù–ê–õ–¨–ù–ê–Ø –°–ï–ì–ú–ï–ù–¢–ê–¶–ò–Ø ‚Äî –ü–û –ü–ê–£–ó–ê–ú –í –ê–£–î–ò–û ‚≠ê
# ============================================================

def segment_by_silence(audio_path: str, full_text: str):
    """
    –î–µ–ª–∏—Ç –∞—É–¥–∏–æ –ø–æ –ø–∞—É–∑–∞–º –∏ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç–µ–∫—Å—Ç –ø–æ —Å–µ–≥–º–µ–Ω—Ç–∞–º.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–µ–≥–º–µ–Ω—Ç—ã –ø–æ–ª–Ω–æ—Å—Ç—å—é –≤ —Å—Ç–∏–ª–µ Whisper CLI.
    """

    audio = AudioSegment.from_wav(audio_path)

    chunks = split_on_silence(
        audio,
        min_silence_len=350,       # –ø–∞—É–∑–∞ ‚â• 0.35 —Å–µ–∫ = –≥—Ä–∞–Ω–∏—Ü–∞ —Ñ—Ä–∞–∑—ã
        silence_thresh=-40,        # –ø–æ—Ä–æ–≥ —Ç–∏—à–∏–Ω—ã
        keep_silence=120           # —Å–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–µ–±–æ–ª—å—à–æ–π —Ö–≤–æ—Å—Ç —Ç–∏—à–∏–Ω—ã
    )

    if not chunks:
        # fallback: –æ–¥–∏–Ω —Å–µ–≥–º–µ–Ω—Ç
        return [{
            "id": 0,
            "start": 0.0,
            "end": len(audio) / 1000,
            "text": full_text.strip()
        }]

    def _split_sentences(text: str):
        pattern = re.compile(r"[^.!?‚Ä¶]+(?:[.!?‚Ä¶]+|$)")
        return [s.strip() for s in pattern.findall(text) if s.strip()]

    def _word_count(phrase: str) -> int:
        return len([w for w in phrase.split() if w])

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º start/end –∫–∞–∂–¥–æ–≥–æ —Å–µ–≥–º–µ–Ω—Ç–∞
    segments = []
    cursor = 0
    for chunk in chunks:
        start = cursor
        end = cursor + len(chunk)
        segments.append((start, end))
        cursor = end

    durations = [end - start for start, end in segments]
    total_duration = sum(durations) or 1

    sentences = _split_sentences(full_text)
    sentence_counts = [(sentence, _word_count(sentence)) for sentence in sentences]
    remaining_words = sum(count for _, count in sentence_counts)

    whisper_segments = []

    for idx, (start, end) in enumerate(segments):
        remaining_segments = len(segments) - idx

        if not sentence_counts:
            break

        if remaining_segments == 1:
            picked = sentence_counts
            sentence_counts = []
        else:
            remaining_duration = sum(durations[idx:]) or total_duration
            target = max(1, round(remaining_words * durations[idx] / remaining_duration))

            picked = []
            picked_words = 0

            while sentence_counts:
                # –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ–º, —á—Ç–æ –≤–ø–µ—Ä–µ–¥–∏ –æ—Å—Ç–∞–Ω–µ—Ç—Å—è —Ö–æ—Ç—è –±—ã 1 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –Ω–∞ —Å–µ–≥–º–µ–Ω—Ç
                if len(sentence_counts) <= (remaining_segments - 1) and picked:
                    break

                sentence, count = sentence_counts[0]

                # –µ—Å–ª–∏ —É–∂–µ –µ—Å—Ç—å —Ç–µ–∫—Å—Ç –∏ —Å–ª–µ–¥—É—é—â–∞—è —Ñ—Ä–∞–∑–∞ –≤—ã–±–∏–≤–∞–µ—Ç—Å—è –∏–∑ –æ–∫–Ω–∞ ‚Äî –∑–∞–≤–µ—Ä—à–∞–µ–º
                if picked and picked_words + count > target:
                    break

                picked.append(sentence_counts.pop(0))
                picked_words += count

            if not picked:
                picked.append(sentence_counts.pop(0))

        text_part = " ".join(sentence for sentence, _ in picked).strip()

        whisper_segments.append({
            "id": len(whisper_segments),
            "start": start / 1000,
            "end": end / 1000,
            "text": text_part
        })

        remaining_words -= sum(count for _, count in picked)

    return whisper_segments


# ============================================================
# ‚≠ê 2. AssemblyAI ‚Äî –ø–æ–ª—É—á–∞–µ–º —Ç–µ–∫—Å—Ç, –Ω–æ —Å–µ–≥–º–µ–Ω—Ç—ã —É–∂–µ –ù–ï –∏—Å–ø–æ–ª—å–∑—É–µ–º ‚≠ê
# ============================================================

def _transcribe_with_assemblyai(audio_path, expected_language=None):
    if not ASSEMBLYAI_API_KEY:
        raise RuntimeError("‚ùå ASSEMBLYAI_API_KEY is missing")

    headers = {"authorization": ASSEMBLYAI_API_KEY}

    def _read_file(path):
        with open(path, "rb") as f:
            while chunk := f.read(5_242_880):
                yield chunk

    print("‚¨ÜÔ∏è  Uploading audio to AssemblyAI...")
    upload_resp = requests.post(
        f"{ASSEMBLYAI_API_URL}/upload",
        headers=headers,
        data=_read_file(audio_path)
    )
    upload_resp.raise_for_status()
    audio_url = upload_resp.json()["upload_url"]

    payload = {
        "audio_url": audio_url,
        "speech_model": "universal",
        "punctuate": True,
    }
    if expected_language:
        payload["language_code"] = expected_language

    print("üõ∞  Requesting AssemblyAI transcription...")
    resp = requests.post(
        f"{ASSEMBLYAI_API_URL}/transcript",
        json=payload,
        headers=headers
    )
    resp.raise_for_status()
    transcript_id = resp.json()["id"]

    # –ñ–¥–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
    poll_url = f"{ASSEMBLYAI_API_URL}/transcript/{transcript_id}"
    while True:
        poll = requests.get(poll_url, headers=headers).json()
        if poll["status"] == "completed":
            print("‚úÖ AssemblyAI transcription completed")
            break
        if poll["status"] == "error":
            raise RuntimeError(poll.get("error"))
        time.sleep(3)

    full_text = poll.get("text", "").strip()

    # ‚≠ê –ü–æ–¥—Å—Ç–∞–≤–ª—è–µ–º –ù–ê–®–ò —Å–µ–≥–º–µ–Ω—Ç—ã ‚Äî –ø–æ —Ç–∏—à–∏–Ω–µ ‚≠ê
    segments = segment_by_silence(audio_path, full_text)

    return {
        "text": full_text,
        "language": poll.get("language_code", expected_language),
        "segments": segments,
        "duration": poll.get("audio_duration")
    }


# ============================================================
# ‚≠ê 3. Whisper API (–±–µ–∑ —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –≤ API) ‚≠ê
# ============================================================

def _transcribe_with_whisper(audio_path, expected_language=None):
    with open(audio_path, "rb") as f:
        response = client.audio.transcriptions.create(
            model="whisper-1",
            file=f,
            response_format="verbose_json"
        )
    result = response.model_dump()

    # Whisper API –Ω–µ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–µ–≥–º–µ–Ω—Ç—ã ‚Äî –¥–µ–ª–∞–µ–º —Å–∞–º–∏
    full_text = result.get("text", "")
    segments = segment_by_silence(audio_path, full_text)

    result["segments"] = segments
    return result


# ============================================================
# ‚≠ê 4. –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è whisper_transcribe() ‚≠ê
# ============================================================

def whisper_transcribe(audio_file="input.wav", expected_language=None):
    audio_path = os.path.join(AUDIO_DIR, audio_file)

    if not os.path.exists(audio_path):
        raise FileNotFoundError(f"‚ùå Audio file not found ‚Üí {audio_path}")

    provider = TRANSCRIBE_PROVIDER.lower()
    print(f"üéß Transcribing using {provider}: {audio_path}")

    if provider == "whisper":
        whisper_json = _transcribe_with_whisper(audio_path, expected_language)
    else:
        whisper_json = _transcribe_with_assemblyai(audio_path, expected_language)

    os.makedirs(WHISPER_DIR, exist_ok=True)

    json_path = os.path.join(WHISPER_DIR, "transcript.json")
    txt_path = os.path.join(WHISPER_DIR, "transcript.txt")

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º
    with open(json_path, "w", encoding="utf-8") as jf:
        json.dump(whisper_json, jf, ensure_ascii=False, indent=2)

    with open(txt_path, "w", encoding="utf-8") as tf:
        tf.write(whisper_json.get("text", ""))

    print("üìÑ JSON saved")
    print("üìù TXT saved")

    # –í–∞–ª–∏–¥–∞—Ü–∏—è
    assert_valid_whisper(json_path, expected_language)

    # –û—á–∏—Å—Ç–∫–∞ GPT
    whisper_json = clean_segments_with_gpt(whisper_json)
    with open(json_path, "w", encoding="utf-8") as jf:
        json.dump(whisper_json, jf, indent=2, ensure_ascii=False)

    print("üü¢ Whisper validation PASSED")
    return json_path


if __name__ == "__main__":
    whisper_transcribe(expected_language="ar")
