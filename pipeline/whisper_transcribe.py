import json
import os
import time
import requests
from openai import OpenAI
from config import OPENAI_API_KEY, ASSEMBLYAI_API_KEY, TRANSCRIBE_PROVIDER
from pipeline.constants import WHISPER_DIR, AUDIO_DIR
from helpers.validators import assert_valid_whisper
from helpers.gpt_cleaner import clean_segments_with_gpt

from pydub import AudioSegment
from pydub.silence import split_on_silence

client = OpenAI(api_key=OPENAI_API_KEY)
ASSEMBLYAI_API_URL = "https://api.assemblyai.com/v2"


# ============================================================
# ‚≠ê 1. –ü–†–û–§–ï–°–°–ò–û–ù–ê–õ–¨–ù–ê–Ø –°–ï–ì–ú–ï–ù–¢–ê–¶–ò–Ø ‚Äî –ü–û –ü–ê–£–ó–ê–ú –í –ê–£–î–ò–û ‚≠ê
# ============================================================

def segment_by_silence(audio_path: str, full_text: str):
    """
    –î–µ–ª–∏—Ç –∞—É–¥–∏–æ –ø–æ –ø–∞—É–∑–∞–º –∏ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç–µ–∫—Å—Ç –ø–æ —Å–µ–≥–º–µ–Ω—Ç–∞–º.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–µ–≥–º–µ–Ω—Ç—ã –ø–æ–ª–Ω–æ—Å—Ç—å—é –≤ —Å—Ç–∏–ª–µ Whisper CLI.
    """

    audio = AudioSegment.from_wav(audio_path)

    chunks = split_on_silence(
        audio,
        min_silence_len=350,       # –ø–∞—É–∑–∞ ‚â• 0.35 —Å–µ–∫ = –≥—Ä–∞–Ω–∏—Ü–∞ —Ñ—Ä–∞–∑—ã
        silence_thresh=-40,        # –ø–æ—Ä–æ–≥ —Ç–∏—à–∏–Ω—ã
        keep_silence=120           # —Å–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–µ–±–æ–ª—å—à–æ–π —Ö–≤–æ—Å—Ç —Ç–∏—à–∏–Ω—ã
    )

    if not chunks:
        # fallback: –æ–¥–∏–Ω —Å–µ–≥–º–µ–Ω—Ç
        return [{
            "id": 0,
            "start": 0.0,
            "end": len(audio) / 1000,
            "text": full_text.strip()
        }]

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º start/end –∫–∞–∂–¥–æ–≥–æ —Å–µ–≥–º–µ–Ω—Ç–∞
    segments = []
    cursor = 0
    for chunk in chunks:
        start = cursor
        end = cursor + len(chunk)
        segments.append((start, end))
        cursor = end

    # –¢–µ–∫—Å—Ç –¥–µ–ª–∏–º –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É —Å–µ–≥–º–µ–Ω—Ç–æ–≤
    words = full_text.split()
    chunk_size = max(1, len(words) // len(segments))

    whisper_segments = []
    word_idx = 0

    for i, (start, end) in enumerate(segments):
        chunk_words = words[word_idx: word_idx + chunk_size]
        word_idx += chunk_size

        text_part = " ".join(chunk_words).strip()
        if not text_part:
            continue

        whisper_segments.append({
            "id": len(whisper_segments),
            "start": start / 1000,
            "end": end / 1000,
            "text": text_part
        })

    # –î–æ–±–∞–≤–ª—è–µ–º –æ—Å—Ç–∞—Ç–æ–∫ —Ç–µ–∫—Å—Ç–∞ –≤ –ø–æ—Å–ª–µ–¥–Ω–∏–π —Å–µ–≥–º–µ–Ω—Ç
    if word_idx < len(words):
        whisper_segments[-1]["text"] += " " + " ".join(words[word_idx:])

    return whisper_segments


# ============================================================
# ‚≠ê 2. AssemblyAI ‚Äî –ø–æ–ª—É—á–∞–µ–º —Ç–µ–∫—Å—Ç, –Ω–æ —Å–µ–≥–º–µ–Ω—Ç—ã —É–∂–µ –ù–ï –∏—Å–ø–æ–ª—å–∑—É–µ–º ‚≠ê
# ============================================================

def _transcribe_with_assemblyai(audio_path, expected_language=None):
    if not ASSEMBLYAI_API_KEY:
        raise RuntimeError("‚ùå ASSEMBLYAI_API_KEY is missing")

    headers = {"authorization": ASSEMBLYAI_API_KEY}

    def _read_file(path):
        with open(path, "rb") as f:
            while chunk := f.read(5_242_880):
                yield chunk

    print("‚¨ÜÔ∏è  Uploading audio to AssemblyAI...")
    upload_resp = requests.post(
        f"{ASSEMBLYAI_API_URL}/upload",
        headers=headers,
        data=_read_file(audio_path)
    )
    upload_resp.raise_for_status()
    audio_url = upload_resp.json()["upload_url"]

    payload = {
        "audio_url": audio_url,
        "speech_model": "universal",
        "punctuate": True,
    }
    if expected_language:
        payload["language_code"] = expected_language

    print("üõ∞  Requesting AssemblyAI transcription...")
    resp = requests.post(
        f"{ASSEMBLYAI_API_URL}/transcript",
        json=payload,
        headers=headers
    )
    resp.raise_for_status()
    transcript_id = resp.json()["id"]

    # –ñ–¥–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
    poll_url = f"{ASSEMBLYAI_API_URL}/transcript/{transcript_id}"
    while True:
        poll = requests.get(poll_url, headers=headers).json()
        if poll["status"] == "completed":
            print("‚úÖ AssemblyAI transcription completed")
            break
        if poll["status"] == "error":
            raise RuntimeError(poll.get("error"))
        time.sleep(3)

    full_text = poll.get("text", "").strip()

    # ‚≠ê –ü–æ–¥—Å—Ç–∞–≤–ª—è–µ–º –ù–ê–®–ò —Å–µ–≥–º–µ–Ω—Ç—ã ‚Äî –ø–æ —Ç–∏—à–∏–Ω–µ ‚≠ê
    segments = segment_by_silence(audio_path, full_text)

    return {
        "text": full_text,
        "language": poll.get("language_code", expected_language),
        "segments": segments,
        "duration": poll.get("audio_duration")
    }


# ============================================================
# ‚≠ê 3. Whisper API (–±–µ–∑ —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –≤ API) ‚≠ê
# ============================================================

def _transcribe_with_whisper(audio_path, expected_language=None):
    with open(audio_path, "rb") as f:
        response = client.audio.transcriptions.create(
            model="whisper-1",
            file=f,
            response_format="verbose_json"
        )
    result = response.model_dump()

    # Whisper API –Ω–µ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–µ–≥–º–µ–Ω—Ç—ã ‚Äî –¥–µ–ª–∞–µ–º —Å–∞–º–∏
    full_text = result.get("text", "")
    segments = segment_by_silence(audio_path, full_text)

    result["segments"] = segments
    return result


# ============================================================
# ‚≠ê 4. –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è whisper_transcribe() ‚≠ê
# ============================================================

def whisper_transcribe(audio_file="input.wav", expected_language=None):
    audio_path = os.path.join(AUDIO_DIR, audio_file)

    if not os.path.exists(audio_path):
        raise FileNotFoundError(f"‚ùå Audio file not found ‚Üí {audio_path}")

    provider = TRANSCRIBE_PROVIDER.lower()
    print(f"üéß Transcribing using {provider}: {audio_path}")

    if provider == "whisper":
        whisper_json = _transcribe_with_whisper(audio_path, expected_language)
    else:
        whisper_json = _transcribe_with_assemblyai(audio_path, expected_language)

    os.makedirs(WHISPER_DIR, exist_ok=True)

    json_path = os.path.join(WHISPER_DIR, "transcript.json")
    txt_path = os.path.join(WHISPER_DIR, "transcript.txt")

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º
    with open(json_path, "w", encoding="utf-8") as jf:
        json.dump(whisper_json, jf, ensure_ascii=False, indent=2)

    with open(txt_path, "w", encoding="utf-8") as tf:
        tf.write(whisper_json.get("text", ""))

    print("üìÑ JSON saved")
    print("üìù TXT saved")

    # –í–∞–ª–∏–¥–∞—Ü–∏—è
    assert_valid_whisper(json_path, expected_language)

    # –û—á–∏—Å—Ç–∫–∞ GPT
    whisper_json = clean_segments_with_gpt(whisper_json)
    with open(json_path, "w", encoding="utf-8") as jf:
        json.dump(whisper_json, jf, indent=2, ensure_ascii=False)

    print("üü¢ Whisper validation PASSED")
    return json_path


if __name__ == "__main__":
    whisper_transcribe(expected_language="ar")
