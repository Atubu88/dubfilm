import json
import os
from openai import OpenAI
from config import OPENAI_API_KEY
from pipeline.constants import WHISPER_DIR, AUDIO_DIR

from helpers.validators import assert_valid_whisper
from helpers.gpt_cleaner import clean_segments_with_gpt
from helpers.cleaning_utils import is_garbage_arabic
from helpers.vad_filter import filter_segments_by_vad

client = OpenAI(api_key=OPENAI_API_KEY)


def whisper_transcribe(audio_file="input.wav", expected_language=None):
    audio_path = os.path.join(AUDIO_DIR, audio_file)

    if not os.path.exists(audio_path):
        raise FileNotFoundError(f"‚ùå ERROR: Audio file not found ‚Üí {audio_path}")

    print(f"üéß Transcribing: {audio_path}")

    # -------------------------
    # 1) –ó–∞–ø—É—Å–∫ Whisper
    # -------------------------
    with open(audio_path, "rb") as f:
        response = client.audio.transcriptions.create(
            model="whisper-1",
            file=f,
            response_format="verbose_json"
        )

    whisper_json = response.model_dump()

    # -------------------------
    # 2) –°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Å—ã—Ä–æ–π Whisper JSON (–¥–æ —Ñ–∏–ª—å—Ç—Ä–æ–≤)
    # -------------------------
    os.makedirs(WHISPER_DIR, exist_ok=True)

    json_path = os.path.join(WHISPER_DIR, "transcript.json")
    txt_path = os.path.join(WHISPER_DIR, "transcript.txt")

    with open(json_path, "w", encoding="utf-8") as jf:
        json.dump(whisper_json, jf, ensure_ascii=False, indent=2)

    with open(txt_path, "w", encoding="utf-8") as tf:
        tf.write(whisper_json.get("text", ""))

    # -------------------------
    # 3) Strict Whisper validation
    # -------------------------
    # –í–ê–ñ–ù–û: –≤–∞–ª–∏–¥–∏—Ä—É–µ–º –¥–æ –ª—é–±—ã—Ö —Ñ–∏–ª—å—Ç—Ä–æ–≤ (VAD –º–æ–∂–µ—Ç –¥–µ–ª–∞—Ç—å –ø—É—Å—Ç—ã–µ —Å–µ–≥–º–µ–Ω—Ç—ã)
    assert_valid_whisper(json_path, expected_language)

    # -------------------------
    # 4) VAD + –∞—Ä–∞–±—Å–∫–∏–π –º—É—Å–æ—Ä
    # -------------------------
    segments = whisper_json.get("segments", [])

    # 4a) –£–±–∏—Ä–∞–µ–º —Å–µ–≥–º–µ–Ω—Ç—ã –±–µ–∑ —Ä–µ–∞–ª—å–Ω–æ–π —Ä–µ—á–∏
    segments = filter_segments_by_vad(segments, audio_path)

    # 4b) –£–±–∏—Ä–∞–µ–º –∞—Ä–∞–±—Å–∫–∏–π "—à—É–º" (—Ö–∞, –∞–∞, –º–º, –≤–æ–∫–∞–ª–∏–∑–∞—Ü–∏–∏)
    cleaned_segments = []
    for seg in segments:
        text = seg.get("text", "")

        if is_garbage_arabic(text):
            seg["text"] = ""

        cleaned_segments.append(seg)

    whisper_json["segments"] = cleaned_segments
    whisper_json["text"] = " ".join(
        seg["text"].strip() for seg in cleaned_segments if seg.get("text")
    )

    # -------------------------
    # 5) GPT-cleaner
    # -------------------------
    whisper_json = clean_segments_with_gpt(whisper_json)

    # -------------------------
    # 6) –ü–µ—Ä–µ—Å–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π Whisper JSON
    # -------------------------
    with open(json_path, "w", encoding="utf-8") as jf:
        json.dump(whisper_json, jf, ensure_ascii=False, indent=2)

    with open(txt_path, "w", encoding="utf-8") as tf:
        tf.write(whisper_json.get("text", ""))

    print("üü¢ Whisper validation PASSED (after cleaning)")
    return json_path


if __name__ == "__main__":
    whisper_transcribe(expected_language="ar")
